{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\AKMAL SK MD\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D , MaxPooling2D , Flatten , Activation , Dense , Dropout , BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam , Adamax\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = r\"C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa vidyapeetham\\Desktop\\DATASET\\Training\"\n",
    "filepaths =[]\n",
    "labels = []\n",
    "folds = os.listdir(train_data_path)\n",
    "\n",
    "for fold in folds:\n",
    "    f_path = os.path.join(train_data_path , fold)\n",
    "    filelists = os.listdir(f_path)\n",
    "    \n",
    "    for file in filelists:\n",
    "        filepaths.append(os.path.join(f_path , file))\n",
    "        labels.append(fold)\n",
    "        \n",
    "Fseries = pd.Series(filepaths , name = 'filepaths')\n",
    "Lseries = pd.Series(labels , name = 'label')\n",
    "train_df = pd.concat([Fseries , Lseries] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...</td>\n",
       "      <td>glioma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...</td>\n",
       "      <td>glioma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...</td>\n",
       "      <td>glioma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...</td>\n",
       "      <td>glioma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...</td>\n",
       "      <td>glioma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...</td>\n",
       "      <td>pituitary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...</td>\n",
       "      <td>pituitary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709</th>\n",
       "      <td>C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...</td>\n",
       "      <td>pituitary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...</td>\n",
       "      <td>pituitary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5711</th>\n",
       "      <td>C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...</td>\n",
       "      <td>pituitary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5712 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filepaths      label\n",
       "0     C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...     glioma\n",
       "1     C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...     glioma\n",
       "2     C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...     glioma\n",
       "3     C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...     glioma\n",
       "4     C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...     glioma\n",
       "...                                                 ...        ...\n",
       "5707  C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...  pituitary\n",
       "5708  C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...  pituitary\n",
       "5709  C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...  pituitary\n",
       "5710  C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...  pituitary\n",
       "5711  C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa ...  pituitary\n",
       "\n",
       "[5712 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           image_vector      label\n",
      "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     glioma\n",
      "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     glioma\n",
      "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     glioma\n",
      "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     glioma\n",
      "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     glioma\n",
      "...                                                 ...        ...\n",
      "5707  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  pituitary\n",
      "5708  [0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, ...  pituitary\n",
      "5709  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...  pituitary\n",
      "5710  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  pituitary\n",
      "5711  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  pituitary\n",
      "\n",
      "[5712 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_data_path = r\"C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa vidyapeetham\\Desktop\\DATASET\\Training\"\n",
    "filepaths = []\n",
    "labels = []\n",
    "folds = os.listdir(train_data_path)\n",
    "\n",
    "for fold in folds:\n",
    "    f_path = os.path.join(train_data_path, fold)\n",
    "    filelists = os.listdir(f_path)\n",
    "    \n",
    "    for file in filelists:\n",
    "        filepaths.append(os.path.join(f_path, file))\n",
    "        labels.append(fold)\n",
    "\n",
    "images = []\n",
    "for filepath in filepaths:\n",
    "    img = cv2.imread(filepath)\n",
    "    # Resize the image to a fixed size\n",
    "    img = cv2.resize(img, (100, 100))  # Adjust the size as needed\n",
    "    img_vector = img.flatten()\n",
    "    # Append the image vector to the list\n",
    "    images.append(img_vector)\n",
    "\n",
    "# Convert the images list to a numpy array\n",
    "images_array = np.array(images)\n",
    "\n",
    "# Create DataFrame\n",
    "Fseries = pd.Series(images_array.tolist(), name='image_vector')\n",
    "Lseries = pd.Series(labels, name='label')\n",
    "train_df = pd.concat([Fseries, Lseries], axis=1)\n",
    "\n",
    "print(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intraclass Spread (Standard Deviation):\n",
      "glioma: [0.10276846 0.10276846 0.10276846 ... 0.07269587 0.07269587 0.07269587]\n",
      "meningioma: [ 9.79214224  9.79214224  9.79214224 ... 10.43629164 10.43629164\n",
      " 10.43629164]\n",
      "notumor: [33.97686755 33.66410904 33.59559123 ... 37.60917814 37.33283787\n",
      " 37.2738257 ]\n",
      "pituitary: [5.03742469 5.03742469 5.03742469 ... 3.94969365 3.94969365 3.94969365]\n",
      "\n",
      "Interclass Distances between Mean Vectors:\n",
      "glioma - meningioma: 2140.8735005671606\n",
      "glioma - notumor: 5444.0055166350985\n",
      "glioma - pituitary: 3872.8915382706755\n",
      "meningioma - notumor: 3553.2791063564077\n",
      "meningioma - pituitary: 2893.868747047778\n",
      "notumor - pituitary: 3949.006525918204\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming this code was executed before\n",
    "train_data_path = r\"C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa vidyapeetham\\Desktop\\DATASET\\Training\"\n",
    "filepaths = []\n",
    "labels = []\n",
    "folds = os.listdir(train_data_path)\n",
    "\n",
    "for fold in folds:\n",
    "    f_path = os.path.join(train_data_path, fold)\n",
    "    filelists = os.listdir(f_path)\n",
    "    \n",
    "    for file in filelists:\n",
    "        filepaths.append(os.path.join(f_path, file))\n",
    "        labels.append(fold)\n",
    "\n",
    "# Initialize empty lists to store image data\n",
    "images = []\n",
    "for filepath in filepaths:\n",
    "    # Read image using OpenCV\n",
    "    img = cv2.imread(filepath)\n",
    "    # Resize the image to a fixed size\n",
    "    img = cv2.resize(img, (100, 100)) \n",
    "    img_vector = img.flatten()\n",
    "    # Append the image vector to the list\n",
    "    images.append(img_vector)\n",
    "\n",
    "# Convert the images list to a numpy array\n",
    "images_array = np.array(images)\n",
    "\n",
    "# Create DataFrame\n",
    "Fseries = pd.Series(images_array.tolist(), name='image_vector')\n",
    "Lseries = pd.Series(labels, name='label')\n",
    "train_df = pd.concat([Fseries, Lseries], axis=1)\n",
    "\n",
    "# Calculate intraclass spread and interclass distances\n",
    "class_labels = train_df['label'].unique()\n",
    "\n",
    "# Initialize empty dictionaries to store mean vectors and spread vectors for each class\n",
    "class_mean_vectors = {}\n",
    "class_spread_vectors = {}\n",
    "\n",
    "# Calculate mean vector and spread vector for each class\n",
    "for label in class_labels:\n",
    "    # Filter images belonging to the current class\n",
    "    class_images = train_df[train_df['label'] == label]['image_vector']\n",
    "    \n",
    "    # Convert the image vectors to NumPy arrays\n",
    "    class_images_array = np.array([np.array(image) for image in class_images])\n",
    "    \n",
    "    # Calculate mean vector for the current class\n",
    "    mean_vector = np.mean(class_images_array, axis=0)\n",
    "    class_mean_vectors[label] = mean_vector\n",
    "    \n",
    "    # Calculate spread vector for the current class\n",
    "    spread_vector = np.std(class_images_array, axis=0)\n",
    "    class_spread_vectors[label] = spread_vector\n",
    "\n",
    "# Calculate interclass distances between mean vectors\n",
    "interclass_distances = {}\n",
    "for i in range(len(class_labels)):\n",
    "    for j in range(i + 1, len(class_labels)):\n",
    "        class1 = class_labels[i]\n",
    "        class2 = class_labels[j]\n",
    "        centroid1 = class_mean_vectors[class1]\n",
    "        centroid2 = class_mean_vectors[class2]\n",
    "        distance = np.linalg.norm(centroid1 - centroid2)\n",
    "        interclass_distances[(class1, class2)] = distance\n",
    "\n",
    "# Print intraclass spread and interclass distances\n",
    "print(\"Intraclass Spread (Standard Deviation):\")\n",
    "for label, spread_vector in class_spread_vectors.items():\n",
    "    print(f\"{label}: {spread_vector}\")\n",
    "\n",
    "print(\"\\nInterclass Distances between Mean Vectors:\")\n",
    "for classes, distance in interclass_distances.items():\n",
    "    print(f\"{classes[0]} - {classes[1]}: {distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 47.19229390756302\n",
      "Variance: 311.43085780228586\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "train_data_path = r\"C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa vidyapeetham\\Desktop\\DATASET\\Training\"\n",
    "filepaths = []\n",
    "labels = []\n",
    "folds = os.listdir(train_data_path)\n",
    "\n",
    "for fold in folds:\n",
    "    f_path = os.path.join(train_data_path, fold)\n",
    "    filelists = os.listdir(f_path)\n",
    "    \n",
    "    for file in filelists:\n",
    "        filepaths.append(os.path.join(f_path, file))\n",
    "        labels.append(fold)\n",
    "\n",
    "images = []\n",
    "for filepath in filepaths:\n",
    "    img = cv2.imread(filepath)\n",
    "    # Resize the image to a fixed size\n",
    "    img = cv2.resize(img, (100, 100))  # Adjust the size as needed\n",
    "    img_vector = img.flatten()\n",
    "    # Append the feature (for example, pixel intensity) to the list\n",
    "    feature_value = np.mean(img_vector)  # Example: using mean pixel intensity as the feature\n",
    "    images.append(feature_value)\n",
    "\n",
    "# Convert the feature values list to a numpy array\n",
    "feature_array = np.array(images)\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(feature_array, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Feature')\n",
    "plt.xlabel('Feature Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean and variance\n",
    "mean_value = np.mean(feature_array)\n",
    "variance_value = np.var(feature_array)\n",
    "\n",
    "print(f\"Mean: {mean_value}\")\n",
    "print(f\"Variance: {variance_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "train_data_path = r\"C:\\Users\\AKMAL SK MD\\OneDrive - Amrita vishwa vidyapeetham\\Desktop\\DATASET\\Training\"\n",
    "filepaths = []\n",
    "labels = []\n",
    "folds = os.listdir(train_data_path)\n",
    "\n",
    "for fold in folds:\n",
    "    f_path = os.path.join(train_data_path, fold)\n",
    "    filelists = os.listdir(f_path)\n",
    "    \n",
    "    for file in filelists:\n",
    "        filepaths.append(os.path.join(f_path, file))\n",
    "        labels.append(fold)\n",
    "\n",
    "images = []\n",
    "for filepath in filepaths:\n",
    "    img = cv2.imread(filepath)\n",
    "    # Resize the image to a fixed size\n",
    "    img = cv2.resize(img, (100, 100))  # Adjust the size as needed\n",
    "    img_vector = img.flatten()\n",
    "    # Append the feature vector to the list\n",
    "    images.append(img_vector)\n",
    "\n",
    "# Convert the feature vectors list to a numpy array\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Divide the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " finding AND gate using the suitable Hyperparameters and applying RandomSearchCV()\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best hyperparameters: {'C': 0.0031150633640573133, 'penalty': 'l2'}\n",
      "Best score: 0.8670\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "# Applying RandomSearchCV() for a single perceptron AND gate\n",
    "print(\" finding AND gate using the suitable Hyperparameters and applying RandomSearchCV()\")\n",
    "# Generate a random classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "# Define the model and hyperparameter distributions\n",
    "model = LogisticRegression(random_state=42)\n",
    "param_dist = {'C': uniform(loc=0, scale=4),\n",
    "              'penalty': ['l1', 'l2']}\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, random_state=42,\n",
    "                                   n_jobs=-1, verbose=1)\n",
    "# Fit the RandomizedSearchCV object to the data\n",
    "random_search.fit(X, y)\n",
    "# Print the best hyperparameters and score\n",
    "print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Best score: {random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root node attribute index: 3225\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_entropy(y):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a given target variable.\n",
    "    \"\"\"\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))  # Add a small value to avoid log(0)\n",
    "    return entropy\n",
    "\n",
    "def calculate_information_gain(X, y, feature_idx):\n",
    "    \"\"\"\n",
    "    Calculate the information gain for a specific feature.\n",
    "    \"\"\"\n",
    "    # Calculate total entropy before split\n",
    "    total_entropy = calculate_entropy(y)\n",
    "    \n",
    "    # Calculate entropy after split based on the feature\n",
    "    unique_values, counts = np.unique(X[:, feature_idx], return_counts=True)\n",
    "    weighted_entropy = 0\n",
    "    for value, count in zip(unique_values, counts):\n",
    "        subset_y = y[X[:, feature_idx] == value]\n",
    "        subset_entropy = calculate_entropy(subset_y)\n",
    "        weighted_entropy += (count / len(y)) * subset_entropy\n",
    "    \n",
    "    # Calculate information gain\n",
    "    information_gain = total_entropy - weighted_entropy\n",
    "    return information_gain\n",
    "\n",
    "def find_root_node(X, y):\n",
    "    \"\"\"\n",
    "    Find the root node attribute with the highest information gain.\n",
    "    \"\"\"\n",
    "    num_features = X.shape[1]\n",
    "    best_feature_idx = None\n",
    "    best_information_gain = -1\n",
    "    \n",
    "    for i in range(num_features):\n",
    "        information_gain = calculate_information_gain(X, y, i)\n",
    "        if information_gain > best_information_gain:\n",
    "            best_information_gain = information_gain\n",
    "            best_feature_idx = i\n",
    "    \n",
    "    return best_feature_idx\n",
    "\n",
    "\n",
    "# Find the root node attribute with the highest information gain\n",
    "root_node_idx = find_root_node(X_train, y_train)\n",
    "print(\"Root node attribute index:\", root_node_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binned feature (Equal Width - Default Bins): [ 4  6  5  7  4  8  2  9  7  7  9  3  7  4  5  6  4  2  3  8  9  3  3 10\n",
      "  7  4  4  5  3  9  4  4  9  4  5  2  9  4  7 10  7  4  4  4  3 10  9  7\n",
      "  5  3 11  4  6  6  3  9  4  6  5  6  2  2  5  6  7  8  1  3  6  5  2  2\n",
      "  6  5 10  7  4  3  5  6  6  3  8  7  3  4  5  5  1 10  7  1  4  4  4  1\n",
      "  8  7  8  9]\n",
      "Binned feature (Equal Width - 5 Bins): [2 3 3 4 2 4 1 5 4 4 5 2 4 2 3 3 2 1 2 4 5 2 2 5 4 2 2 3 2 5 2 2 5 2 3 1 5\n",
      " 2 4 5 4 2 2 2 2 5 5 4 3 2 6 2 3 3 2 5 2 3 3 3 1 1 3 3 4 4 1 2 3 3 1 1 3 3\n",
      " 5 4 2 2 3 3 3 2 4 4 2 2 3 3 1 5 4 1 2 2 2 1 4 4 4 5]\n",
      "Binned feature (Frequency - Default Bins): [ 4  6  5  7  4  8  2  9  7  7  9  3  7  4  5  6  4  2  3  8  9  3  3 10\n",
      "  7  4  4  5  3  9  4  4  9  4  5  2  9  4  7 10  7  4  4  4  3 10  9  7\n",
      "  5  3 11  4  6  6  3  9  4  6  5  6  2  2  5  6  7  8  1  3  6  5  2  2\n",
      "  6  5 10  7  4  3  5  6  6  3  8  7  3  4  5  5  1 10  7  1  4  4  4  1\n",
      "  8  7  8  9]\n",
      "Binned feature (Frequency - 5 Bins): [2 3 3 4 2 4 1 5 4 4 5 2 4 2 3 3 2 1 2 4 5 2 2 5 4 2 2 3 2 5 2 2 5 2 3 1 5\n",
      " 2 4 5 4 2 2 2 2 5 5 4 3 2 6 2 3 3 2 5 2 3 3 3 1 1 3 3 4 4 1 2 3 3 1 1 3 3\n",
      " 5 4 2 2 3 3 3 2 4 4 2 2 3 3 1 5 4 1 2 2 2 1 4 4 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bin_continuous_feature(feature, bins=None, binning_type='equal_width'):\n",
    "    \"\"\"\n",
    "    Bins a continuous-valued feature into categorical values.\n",
    "\n",
    "    Parameters:\n",
    "    - feature: numpy array, the continuous-valued feature to be binned.\n",
    "    - bins: int or list, optional, the number of bins to create or the bin edges.\n",
    "            If None, default to 10 bins.\n",
    "    - binning_type: str, optional, the type of binning to perform.\n",
    "                    Can be 'equal_width' or 'frequency'. Default is 'equal_width'.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array, the binned feature with categorical values.\n",
    "    \"\"\"\n",
    "    if binning_type == 'equal_width':\n",
    "        if bins is None:\n",
    "            bins = 10\n",
    "        return np.digitize(feature, np.linspace(feature.min(), feature.max(), bins + 1))\n",
    "\n",
    "    elif binning_type == 'frequency':\n",
    "        if bins is None:\n",
    "            bins = 10\n",
    "        return np.digitize(feature, np.histogram_bin_edges(feature, bins=bins))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid binning_type. Choose 'equal_width' or 'frequency'.\")\n",
    "\n",
    "# Example usage:\n",
    "# Generate some continuous-valued feature data\n",
    "continuous_feature = np.random.randn(100)\n",
    "\n",
    "# Bin the continuous feature using equal width binning with default number of bins\n",
    "binned_feature_equal_width_default = bin_continuous_feature(continuous_feature)\n",
    "print(\"Binned feature (Equal Width - Default Bins):\", binned_feature_equal_width_default)\n",
    "\n",
    "# Bin the continuous feature using equal width binning with 5 bins\n",
    "binned_feature_equal_width_5_bins = bin_continuous_feature(continuous_feature, bins=5)\n",
    "print(\"Binned feature (Equal Width - 5 Bins):\", binned_feature_equal_width_5_bins)\n",
    "\n",
    "# Bin the continuous feature using frequency binning with default number of bins\n",
    "binned_feature_frequency_default = bin_continuous_feature(continuous_feature, binning_type='frequency')\n",
    "print(\"Binned feature (Frequency - Default Bins):\", binned_feature_frequency_default)\n",
    "\n",
    "# Bin the continuous feature using frequency binning with 5 bins\n",
    "binned_feature_frequency_5_bins = bin_continuous_feature(continuous_feature, bins=5, binning_type='frequency')\n",
    "print(\"Binned feature (Frequency - 5 Bins):\", binned_feature_frequency_5_bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: {0: <__main__.TreeNode object at 0x00000229CBD30950>, 1: <__main__.TreeNode object at 0x00000229CBD0E610>, 2: <__main__.TreeNode object at 0x00000229CBD939D0>, 3: <__main__.TreeNode object at 0x00000229CBDAEED0>, 4: <__main__.TreeNode object at 0x00000229CBDC4490>, 5: <__main__.TreeNode object at 0x00000229CBDD2690>, 6: <__main__.TreeNode object at 0x00000229CBDD7450>, 7: <__main__.TreeNode object at 0x00000229CBDE3450>, 8: <__main__.TreeNode object at 0x00000229CBDE9690>, 9: <__main__.TreeNode object at 0x00000229CBDEB710>, 10: <__main__.TreeNode object at 0x00000229CBDEC790>, 11: <__main__.TreeNode object at 0x00000229CBDED590>, 12: <__main__.TreeNode object at 0x00000229CBDEE090>, 13: <__main__.TreeNode object at 0x00000229CBD25F10>, 14: <__main__.TreeNode object at 0x00000229CBD2D750>, 15: <__main__.TreeNode object at 0x00000229CBD16F90>, 16: <__main__.TreeNode object at 0x00000229CBCBD550>, 17: <__main__.TreeNode object at 0x00000229CBC8A0D0>, 18: <__main__.TreeNode object at 0x00000229CBCDD6D0>, 19: <__main__.TreeNode object at 0x00000229CBC94690>, 20: <__main__.TreeNode object at 0x00000229CBD00FD0>, 21: <__main__.TreeNode object at 0x00000229CBD03390>, 22: <__main__.TreeNode object at 0x00000229CBD02ED0>, 23: <__main__.TreeNode object at 0x00000229CBD00750>, 24: <__main__.TreeNode object at 0x00000229CBCFBED0>, 25: <__main__.TreeNode object at 0x00000229CBCF89D0>, 26: <__main__.TreeNode object at 0x00000229CBCF9B10>, 27: <__main__.TreeNode object at 0x00000229CBCB1C10>, 28: <__main__.TreeNode object at 0x00000229CBCB0B50>, 29: <__main__.TreeNode object at 0x00000229CBCCE750>, 30: <__main__.TreeNode object at 0x00000229CBCDB710>, 31: <__main__.TreeNode object at 0x00000229CBD0B350>, 32: <__main__.TreeNode object at 0x00000229CBD08610>, 33: <__main__.TreeNode object at 0x00000229CBD0AC90>, 34: <__main__.TreeNode object at 0x00000229CBD0A9D0>, 35: <__main__.TreeNode object at 0x00000229CBD09E10>, 36: <__main__.TreeNode object at 0x00000229CBCEF5D0>, 37: <__main__.TreeNode object at 0x00000229CBCEEC10>, 38: <__main__.TreeNode object at 0x00000229CBCEC9D0>, 39: <__main__.TreeNode object at 0x00000229CBCED9D0>, 40: <__main__.TreeNode object at 0x00000229CBCED050>, 41: <__main__.TreeNode object at 0x00000229CBCA9850>, 42: <__main__.TreeNode object at 0x00000229CBCA9F10>, 43: <__main__.TreeNode object at 0x00000229CBCA9DD0>, 44: <__main__.TreeNode object at 0x00000229CBDEE910>, 45: <__main__.TreeNode object at 0x00000229CBDEEB90>, 46: <__main__.TreeNode object at 0x00000229CBDEED10>, 47: <__main__.TreeNode object at 0x00000229CBDEEF10>, 48: <__main__.TreeNode object at 0x00000229CBDEEF90>, 49: <__main__.TreeNode object at 0x00000229CBDEF290>, 50: <__main__.TreeNode object at 0x00000229CBDEF310>, 51: <__main__.TreeNode object at 0x00000229CBDEF590>, 52: <__main__.TreeNode object at 0x00000229CBDEF950>, 53: <__main__.TreeNode object at 0x00000229CBDEFAD0>, 54: <__main__.TreeNode object at 0x00000229CBDEFDD0>, 55: <__main__.TreeNode object at 0x00000229CBDEFE50>, 56: <__main__.TreeNode object at 0x00000229CBDFC090>, 57: <__main__.TreeNode object at 0x00000229CBDFC250>, 58: <__main__.TreeNode object at 0x00000229CBDFC2D0>, 59: <__main__.TreeNode object at 0x00000229CBDFC450>, 60: <__main__.TreeNode object at 0x00000229CBDFC5D0>, 61: <__main__.TreeNode object at 0x00000229CBDFC8D0>, 62: <__main__.TreeNode object at 0x00000229CBDFCCD0>, 63: <__main__.TreeNode object at 0x00000229CBDFCD50>, 64: <__main__.TreeNode object at 0x00000229CBDFCDD0>, 65: <__main__.TreeNode object at 0x00000229CBDFD050>, 66: <__main__.TreeNode object at 0x00000229CBDFD390>, 67: <__main__.TreeNode object at 0x00000229CBDFD410>, 68: <__main__.TreeNode object at 0x00000229CBDFD610>, 69: <__main__.TreeNode object at 0x00000229CBDFD910>, 70: <__main__.TreeNode object at 0x00000229CBDFDBD0>, 71: <__main__.TreeNode object at 0x00000229CBDFDC50>, 72: <__main__.TreeNode object at 0x00000229CBDFDCD0>, 73: <__main__.TreeNode object at 0x00000229CBDFDF50>, 74: <__main__.TreeNode object at 0x00000229CBDFE350>, 75: <__main__.TreeNode object at 0x00000229CBDFE4D0>, 76: <__main__.TreeNode object at 0x00000229CBDFE8D0>, 77: <__main__.TreeNode object at 0x00000229CBDFEDD0>, 78: <__main__.TreeNode object at 0x00000229CBDFF050>, 79: <__main__.TreeNode object at 0x00000229CBDFF0D0>, 80: <__main__.TreeNode object at 0x00000229CBDFF3D0>, 81: <__main__.TreeNode object at 0x00000229CBDFF5D0>, 82: <__main__.TreeNode object at 0x00000229CBDFF750>, 83: <__main__.TreeNode object at 0x00000229CBDFFC50>, 84: <__main__.TreeNode object at 0x00000229CBDFFE10>, 85: <__main__.TreeNode object at 0x00000229CBDFFE90>, 86: <__main__.TreeNode object at 0x00000229CBE0C150>, 87: <__main__.TreeNode object at 0x00000229CBE0C2D0>, 88: <__main__.TreeNode object at 0x00000229CBE0C5D0>, 89: <__main__.TreeNode object at 0x00000229CBE0C650>, 90: <__main__.TreeNode object at 0x00000229CBE0C6D0>, 91: <__main__.TreeNode object at 0x00000229CBE0C810>, 92: <__main__.TreeNode object at 0x00000229CBE0C990>, 93: <__main__.TreeNode object at 0x00000229CBE0CC10>, 94: <__main__.TreeNode object at 0x00000229CBE0CC90>, 96: <__main__.TreeNode object at 0x00000229CBE0CE10>, 97: <__main__.TreeNode object at 0x00000229CBE0CE90>, 98: <__main__.TreeNode object at 0x00000229CBE0CF10>, 99: <__main__.TreeNode object at 0x00000229CBE0CF90>, 100: <__main__.TreeNode object at 0x00000229CBE0D010>, 101: <__main__.TreeNode object at 0x00000229CBE0D090>, 102: <__main__.TreeNode object at 0x00000229CBE0D350>, 103: <__main__.TreeNode object at 0x00000229CBE0D4D0>, 104: <__main__.TreeNode object at 0x00000229CBE0D550>, 105: <__main__.TreeNode object at 0x00000229CBE0D5D0>, 106: <__main__.TreeNode object at 0x00000229CBE0D650>, 107: <__main__.TreeNode object at 0x00000229CBE0D6D0>, 108: <__main__.TreeNode object at 0x00000229CBE0D8D0>, 110: <__main__.TreeNode object at 0x00000229CBE0DA50>, 111: <__main__.TreeNode object at 0x00000229CBE0DAD0>, 112: <__main__.TreeNode object at 0x00000229CBE0DC50>, 113: <__main__.TreeNode object at 0x00000229CBE0DE50>, 114: <__main__.TreeNode object at 0x00000229CBE0DED0>, 115: <__main__.TreeNode object at 0x00000229CBE0E0D0>, 116: <__main__.TreeNode object at 0x00000229CBE0E150>, 117: <__main__.TreeNode object at 0x00000229CBE0E2D0>, 118: <__main__.TreeNode object at 0x00000229CBE0E350>, 119: <__main__.TreeNode object at 0x00000229CBE0E510>, 120: <__main__.TreeNode object at 0x00000229CBE0E690>, 122: <__main__.TreeNode object at 0x00000229CBE0E710>, 123: <__main__.TreeNode object at 0x00000229CBE0E990>, 124: <__main__.TreeNode object at 0x00000229CBE0EA10>, 125: <__main__.TreeNode object at 0x00000229CBE0EA90>, 126: <__main__.TreeNode object at 0x00000229CBE0EB10>, 128: <__main__.TreeNode object at 0x00000229CBE0EB90>, 129: <__main__.TreeNode object at 0x00000229CBE0EC10>, 130: <__main__.TreeNode object at 0x00000229CBE0EDD0>, 131: <__main__.TreeNode object at 0x00000229CBE0F010>, 132: <__main__.TreeNode object at 0x00000229CBE0F210>, 134: <__main__.TreeNode object at 0x00000229CBE0F290>, 135: <__main__.TreeNode object at 0x00000229CBE0F310>, 136: <__main__.TreeNode object at 0x00000229CBE0F4D0>, 137: <__main__.TreeNode object at 0x00000229CBE0F550>, 138: <__main__.TreeNode object at 0x00000229CBE0F5D0>, 139: <__main__.TreeNode object at 0x00000229CBE0F650>, 140: <__main__.TreeNode object at 0x00000229CBE0F6D0>, 141: <__main__.TreeNode object at 0x00000229CBE0F750>, 142: <__main__.TreeNode object at 0x00000229CBE0F7D0>, 143: <__main__.TreeNode object at 0x00000229CBE0FA10>, 144: <__main__.TreeNode object at 0x00000229CBE0FBD0>, 145: <__main__.TreeNode object at 0x00000229CBE0FDD0>, 146: <__main__.TreeNode object at 0x00000229CBE0FE50>, 148: <__main__.TreeNode object at 0x00000229CBE0FED0>, 149: <__main__.TreeNode object at 0x00000229CBE100D0>, 150: <__main__.TreeNode object at 0x00000229CBE10310>, 151: <__main__.TreeNode object at 0x00000229CBE104D0>, 153: <__main__.TreeNode object at 0x00000229CBE10550>, 154: <__main__.TreeNode object at 0x00000229CBE10710>, 155: <__main__.TreeNode object at 0x00000229CBE10910>, 156: <__main__.TreeNode object at 0x00000229CBE10AD0>, 157: <__main__.TreeNode object at 0x00000229CBE10D10>, 159: <__main__.TreeNode object at 0x00000229CBE10D90>, 160: <__main__.TreeNode object at 0x00000229CBE10F50>, 161: <__main__.TreeNode object at 0x00000229CBE10FD0>, 162: <__main__.TreeNode object at 0x00000229CBE11050>, 163: <__main__.TreeNode object at 0x00000229CBE110D0>, 164: <__main__.TreeNode object at 0x00000229CBE11150>, 165: <__main__.TreeNode object at 0x00000229CBE112D0>, 166: <__main__.TreeNode object at 0x00000229CBE11350>, 167: <__main__.TreeNode object at 0x00000229CBE113D0>, 168: <__main__.TreeNode object at 0x00000229CBE11450>, 169: <__main__.TreeNode object at 0x00000229CBE11610>, 170: <__main__.TreeNode object at 0x00000229CBE117D0>, 171: <__main__.TreeNode object at 0x00000229CBE11850>, 172: <__main__.TreeNode object at 0x00000229CBE118D0>, 173: <__main__.TreeNode object at 0x00000229CBE11A90>, 174: <__main__.TreeNode object at 0x00000229CBE11B10>, 175: <__main__.TreeNode object at 0x00000229CBE11CD0>, 176: <__main__.TreeNode object at 0x00000229CBE11D50>, 177: <__main__.TreeNode object at 0x00000229CBE11DD0>, 179: <__main__.TreeNode object at 0x00000229CBE11E50>, 180: <__main__.TreeNode object at 0x00000229CBE11ED0>, 181: <__main__.TreeNode object at 0x00000229CBE12090>, 182: <__main__.TreeNode object at 0x00000229CBE12110>, 183: <__main__.TreeNode object at 0x00000229CBE122D0>, 184: <__main__.TreeNode object at 0x00000229CBE12350>, 185: <__main__.TreeNode object at 0x00000229CBE12510>, 186: <__main__.TreeNode object at 0x00000229CBE12590>, 187: <__main__.TreeNode object at 0x00000229CBE12610>, 188: <__main__.TreeNode object at 0x00000229CBE127D0>, 189: <__main__.TreeNode object at 0x00000229CBE12990>, 190: <__main__.TreeNode object at 0x00000229CBE12A10>, 192: <__main__.TreeNode object at 0x00000229CBE12A90>, 196: <__main__.TreeNode object at 0x00000229CBE12B10>, 197: <__main__.TreeNode object at 0x00000229CBE12CD0>, 198: <__main__.TreeNode object at 0x00000229CBE12E90>, 200: <__main__.TreeNode object at 0x00000229CBE12F10>, 201: <__main__.TreeNode object at 0x00000229CBE13150>, 203: <__main__.TreeNode object at 0x00000229CBE131D0>, 205: <__main__.TreeNode object at 0x00000229CBE13250>, 206: <__main__.TreeNode object at 0x00000229CBE132D0>, 207: <__main__.TreeNode object at 0x00000229CBE13350>, 208: <__main__.TreeNode object at 0x00000229CBE133D0>, 209: <__main__.TreeNode object at 0x00000229CBE13450>, 210: <__main__.TreeNode object at 0x00000229CBE134D0>, 212: <__main__.TreeNode object at 0x00000229CBE13550>, 214: <__main__.TreeNode object at 0x00000229CBE135D0>, 216: <__main__.TreeNode object at 0x00000229CBE13650>, 217: <__main__.TreeNode object at 0x00000229CBE13810>, 219: <__main__.TreeNode object at 0x00000229CBE13890>, 220: <__main__.TreeNode object at 0x00000229CBE13910>, 221: <__main__.TreeNode object at 0x00000229CBE13990>, 223: <__main__.TreeNode object at 0x00000229CBE13A10>, 224: <__main__.TreeNode object at 0x00000229CBE13A90>, 225: <__main__.TreeNode object at 0x00000229CBE13B10>, 226: <__main__.TreeNode object at 0x00000229CBE13CD0>, 227: <__main__.TreeNode object at 0x00000229CBE13F10>, 229: <__main__.TreeNode object at 0x00000229CBE13F90>, 230: <__main__.TreeNode object at 0x00000229CBE18050>, 235: <__main__.TreeNode object at 0x00000229CBE180D0>, 236: <__main__.TreeNode object at 0x00000229CBE18150>, 237: <__main__.TreeNode object at 0x00000229CBE181D0>, 241: <__main__.TreeNode object at 0x00000229CBE18250>, 242: <__main__.TreeNode object at 0x00000229CBE182D0>, 243: <__main__.TreeNode object at 0x00000229CBE18350>, 244: <__main__.TreeNode object at 0x00000229CBE183D0>, 247: <__main__.TreeNode object at 0x00000229CBE18450>, 249: <__main__.TreeNode object at 0x00000229CBE184D0>, 250: <__main__.TreeNode object at 0x00000229CBE18550>, 251: <__main__.TreeNode object at 0x00000229CBE185D0>, 252: <__main__.TreeNode object at 0x00000229CBE18890>, 253: <__main__.TreeNode object at 0x00000229CBE18A50>, 254: <__main__.TreeNode object at 0x00000229CBE18AD0>, 255: <__main__.TreeNode object at 0x00000229CBE18B50>}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, feature_index=None, threshold=None, value=None, left=None, right=None):\n",
    "        self.feature_index = feature_index  # Index of the feature to split on\n",
    "        self.threshold = threshold  # Threshold value for binary split\n",
    "        self.value = value  # Value to predict if leaf node\n",
    "        self.left = left  # Left child node\n",
    "        self.right = right  # Right child node\n",
    "\n",
    "def calculate_entropy(y):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a given target variable.\n",
    "    \"\"\"\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))  # Add a small value to avoid log(0)\n",
    "    return entropy\n",
    "\n",
    "def calculate_information_gain(X, y, feature_idx):\n",
    "    \"\"\"\n",
    "    Calculate the information gain for a specific feature.\n",
    "    \"\"\"\n",
    "    # Calculate total entropy before split\n",
    "    total_entropy = calculate_entropy(y)\n",
    "    \n",
    "    # Calculate entropy after split based on the feature\n",
    "    unique_values, counts = np.unique(X[:, feature_idx], return_counts=True)\n",
    "    weighted_entropy = 0\n",
    "    for value, count in zip(unique_values, counts):\n",
    "        subset_y = y[X[:, feature_idx] == value]\n",
    "        subset_entropy = calculate_entropy(subset_y)\n",
    "        weighted_entropy += (count / len(y)) * subset_entropy\n",
    "    \n",
    "    # Calculate information gain\n",
    "    information_gain = total_entropy - weighted_entropy\n",
    "    return information_gain\n",
    "\n",
    "def bin_continuous_feature(feature, bins=None, binning_type='equal_width'):\n",
    "    \"\"\"\n",
    "    Bins a continuous-valued feature into categorical values.\n",
    "\n",
    "    Parameters:\n",
    "    - feature: numpy array, the continuous-valued feature to be binned.\n",
    "    - bins: int or list, optional, the number of bins to create or the bin edges.\n",
    "            If None, default to 10 bins.\n",
    "    - binning_type: str, optional, the type of binning to perform.\n",
    "                    Can be 'equal_width' or 'frequency'. Default is 'equal_width'.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array, the binned feature with categorical values.\n",
    "    \"\"\"\n",
    "    if binning_type == 'equal_width':\n",
    "        if bins is None:\n",
    "            bins = 10\n",
    "        return np.digitize(feature, np.linspace(feature.min(), feature.max(), bins + 1))\n",
    "\n",
    "    elif binning_type == 'frequency':\n",
    "        if bins is None:\n",
    "            bins = 10\n",
    "        return np.digitize(feature, np.histogram_bin_edges(feature, bins=bins))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid binning_type. Choose 'equal_width' or 'frequency'.\")\n",
    "\n",
    "def find_root_node(X, y, binning_type='equal_width', bins=None):\n",
    "    \"\"\"\n",
    "    Find the root node attribute with the highest information gain.\n",
    "\n",
    "    Parameters:\n",
    "    - X: numpy array, the feature matrix.\n",
    "    - y: numpy array, the target variable.\n",
    "    - binning_type: str, optional, the type of binning to perform.\n",
    "                    Can be 'equal_width' or 'frequency'. Default is 'equal_width'.\n",
    "    - bins: int or list, optional, the number of bins to create or the bin edges.\n",
    "\n",
    "    Returns:\n",
    "    - int, the index of the feature to be used as the root node attribute.\n",
    "    \"\"\"\n",
    "    num_features = X.shape[1]\n",
    "    best_feature_idx = None\n",
    "    best_information_gain = -1\n",
    "    \n",
    "    for i in range(num_features):\n",
    "        if len(np.unique(X[:, i])) == 1:  # Skip features with only one unique value\n",
    "            continue\n",
    "\n",
    "        if np.issubdtype(X[:, i].dtype, np.floating):  # Continuous-valued feature\n",
    "            binned_feature = bin_continuous_feature(X[:, i], bins=bins, binning_type=binning_type)\n",
    "            information_gain = calculate_information_gain(binned_feature, y, i)\n",
    "        else:  # Categorical feature\n",
    "            information_gain = calculate_information_gain(X, y, i)\n",
    "\n",
    "        if information_gain > best_information_gain:\n",
    "            best_information_gain = information_gain\n",
    "            best_feature_idx = i\n",
    "    \n",
    "    return best_feature_idx\n",
    "\n",
    "def build_decision_tree(X, y, binning_type='equal_width', bins=None):\n",
    "    \"\"\"\n",
    "    Build a decision tree recursively.\n",
    "\n",
    "    Parameters:\n",
    "    - X: numpy array, the feature matrix.\n",
    "    - y: numpy array, the target variable.\n",
    "    - binning_type: str, optional, the type of binning to perform.\n",
    "                    Can be 'equal_width' or 'frequency'. Default is 'equal_width'.\n",
    "    - bins: int or list, optional, the number of bins to create or the bin edges.\n",
    "\n",
    "    Returns:\n",
    "    - TreeNode, the root node of the decision tree.\n",
    "    \"\"\"\n",
    "    if len(np.unique(y)) == 1:  # If all samples in node have the same class, return leaf node\n",
    "        return TreeNode(value=y[0])\n",
    "\n",
    "    root_feature_idx = find_root_node(X, y, binning_type=binning_type, bins=bins)\n",
    "\n",
    "    if root_feature_idx is None:  # If no feature provides information gain, return leaf node\n",
    "        return TreeNode(value=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "    if np.issubdtype(X[:, root_feature_idx].dtype, np.floating):  # Continuous-valued feature\n",
    "        binned_feature = bin_continuous_feature(X[:, root_feature_idx], bins=bins, binning_type=binning_type)\n",
    "        threshold = np.median(binned_feature)\n",
    "        left_indices = np.where(binned_feature <= threshold)[0]\n",
    "        right_indices = np.where(binned_feature > threshold)[0]\n",
    "        left_child = build_decision_tree(X[left_indices], y[left_indices], binning_type=binning_type, bins=bins)\n",
    "        right_child = build_decision_tree(X[right_indices], y[right_indices], binning_type=binning_type, bins=bins)\n",
    "        return TreeNode(feature_index=root_feature_idx, threshold=threshold, left=left_child, right=right_child)\n",
    "\n",
    "    else:  # Categorical feature\n",
    "        unique_values = np.unique(X[:, root_feature_idx])\n",
    "        children = {}\n",
    "        for value in unique_values:\n",
    "            indices = np.where(X[:, root_feature_idx] == value)[0]\n",
    "            children[value] = build_decision_tree(X[indices], y[indices], binning_type=binning_type, bins=bins)\n",
    "        return TreeNode(feature_index=root_feature_idx, value=children)\n",
    "\n",
    "# Example usage with the provided dataset\n",
    "# Assuming X_train is your feature matrix and y_train is your target variable\n",
    "# Replace this with your actual dataset\n",
    "\n",
    "# Build the decision tree\n",
    "decision_tree = build_decision_tree(X_train, y_train)\n",
    "\n",
    "# Example usage: Predict using the decision tree\n",
    "def predict(tree, sample):\n",
    "    if tree.value is not None:  # If leaf node, return value\n",
    "        return tree.value\n",
    "    elif np.issubdtype(sample[tree.feature_index].dtype, np.floating):  # Continuous-valued feature\n",
    "        if sample[tree.feature_index] <= tree.threshold:\n",
    "            return predict(tree.left, sample)\n",
    "        else:\n",
    "            return predict(tree.right, sample)\n",
    "    else:  # Categorical feature\n",
    "        child = tree.value.get(sample[tree.feature_index])\n",
    "        if child is None:\n",
    "            return None  # Missing value, return None\n",
    "        else:\n",
    "            return predict(child, sample)\n",
    "\n",
    "# Example usage: Predict using the decision tree\n",
    "sample = np.array(images)\n",
    "print(\"Prediction:\", predict(decision_tree, sample))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
